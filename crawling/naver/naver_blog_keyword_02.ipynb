{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import time, os, random, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from selenium import webdriver\n",
    "import chromedriver_autoinstaller as ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chrome driver 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USB error 메세지 발생 해결을 위한 코드\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "options.add_argument('headless')  # headless 모드 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'131'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재 크롬 버전 확인\n",
    "chrome_ver = ca.get_chrome_version().split('.')[0]\n",
    "chrome_ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 크롬 드라이버 확인 및 설치(처음 한번만 실행)\n",
    "# ca.install(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## requests 테스트\n",
    "- 페이지 접속 가능 여부확인\n",
    "    - 가능할 경우 출력 : <Response [200]>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# req = requests.get(url)\n",
    "# print(req)\n",
    "\n",
    "# 한글 깨짐 해결 코드\n",
    "# # html = req.content.decode('utf-8') # 한글 깨짐 해결\n",
    "# # soup = bs(html, 'html.parser')\n",
    "\n",
    "# soup = bs(req.text, 'html.parser')\n",
    "# soup.title.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검색어 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = '아이폰 16' # 검색어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검색 옵션 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rangetype = 'WEEK' # 검색 범위(기간 전체 : ALL, 최근 1주 : WEEK, 최근 1개월 : MONTH, 기간 입력 : PERIOD)\n",
    "orderby = 'sim' # 정렬 순서(관련도순 : sim, 최신순 : recentdate)\n",
    "\n",
    "# rangetype이 PERIOD인 경우 시작일과 종료일 설정 \n",
    "startdate = '2025-01-01' # 형식: YYYY-mm-dd(예. 2025-01-01)\n",
    "enddate = '2025-01-02' # 형식: YYYY-mm-dd(예. 2025-01-01)\n",
    "current_date = datetime.today().strftime('%Y-%m-%d')\n",
    "if startdate > enddate:\n",
    "    startdate, enddate = enddate, startdate # 시작일이 종료일보다 크면 종료일로 변경\n",
    "if startdate > current_date:\n",
    "    startdate, enddate = current_date, current_date # 시작일이 현재 날짜보다 크면 현재 날짜로 변경\n",
    "if enddate > current_date:\n",
    "    enddate = current_date # 종료일이 현재 날짜보다 크면 현재 날짜로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 봇 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹드라이버 실행\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검색 결과 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색어 : 아이폰 16\n",
      "글/블로그 선택 : 글\n",
      "검색 범위 : 최근 1주\n",
      "정렬 순서 : 관련도순\n",
      "검색 결과 개수 : 363901\n",
      "검색 결과 페이지 수 : 51986\n",
      "\n",
      "==================================================\n",
      "검색어 : 아이폰 16\n",
      "글/블로그 선택 : 블로그\n",
      "정렬 순서 : 관련도순\n",
      "검색 결과 개수 : 198\n",
      "검색 결과 페이지 수 : 20\n"
     ]
    }
   ],
   "source": [
    "# 검색 결과 개수 확인\n",
    "sheet_name_list = ['글', '블로그']\n",
    "for tab_option in sheet_name_list:\n",
    "    page_num = 1\n",
    "    if tab_option == '글':\n",
    "        if rangetype == 'PERIOD':\n",
    "            keyword_url = f'https://section.blog.naver.com/Search/Post.naver?pageNo={page_num}&rangeType={rangetype}&orderBy={orderby}&&startDate={startdate}&endDate={enddate}&keyword={keyword}'\n",
    "        else:\n",
    "            keyword_url = f'https://section.blog.naver.com/Search/Post.naver?pageNo={page_num}&rangeType={rangetype}&orderBy={orderby}&keyword={keyword}'\n",
    "\n",
    "        driver.get(keyword_url)\n",
    "        driver.implicitly_wait(10) # 페이지 로드 될 때까지 기다리지만 로드 되는 순간 종료\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "\n",
    "        page = driver.page_source\n",
    "        soup = bs(page, 'html.parser')\n",
    "        \n",
    "        area_list_search = soup.select_one('div.area_list_search')\n",
    "        list_search_post = area_list_search.select('div.list_search_post')\n",
    "\n",
    "        # 검색 결과 개수\n",
    "        raw_post_search_number = soup.select_one('div.search_information em.search_number').text\n",
    "        post_search_number = int(re.sub('[^0-9]', '', raw_post_search_number))\n",
    "\n",
    "        # 검색 결과 페이지 수\n",
    "        max_post_search_page_num = int(np.ceil(post_search_number / len(list_search_post)))\n",
    "\n",
    "        if rangetype == 'PERIOD':\n",
    "            print('='*50)\n",
    "            print('검색어 :', keyword)\n",
    "            print('글/블로그 선택 :', tab_option)\n",
    "            print('검색 범위 :', rangetype.replace('PERIOD', '기간 입력'))\n",
    "            print('검색 시작일 :', startdate)\n",
    "            print('검색 종료일 :', enddate)\n",
    "            print('정렬 순서 :', orderby.replace('sim', '관련도순').replace('recentdate', '최신순'))\n",
    "            print('검색 결과 개수 :', post_search_number)\n",
    "            print('검색 결과 페이지 수 :', max_post_search_page_num)\n",
    "        else:\n",
    "            print('검색어 :', keyword)\n",
    "            print('글/블로그 선택 :', tab_option)\n",
    "            print('검색 범위 :', rangetype.replace('ALL', '기간 전체').replace('WEEK', '최근 1주').replace('MONTH', '최근 1개월'))\n",
    "            print('정렬 순서 :', orderby.replace('sim', '관련도순').replace('recentdate', '최신순'))\n",
    "            print('검색 결과 개수 :', post_search_number)\n",
    "            print('검색 결과 페이지 수 :', max_post_search_page_num)\n",
    "        print()\n",
    "\n",
    "    elif tab_option == '블로그':\n",
    "        keyword_url = f'https://section.blog.naver.com/Search/Blog.naver?pageNo={page_num}&orderBy={orderby}&keyword={keyword}'\n",
    "\n",
    "        driver.get(keyword_url)\n",
    "        driver.implicitly_wait(10) # 페이지 로드 될 때까지 기다리지만 로드 되는 순간 종료\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "\n",
    "        page = driver.page_source\n",
    "        soup = bs(page, 'html.parser')\n",
    "\n",
    "        area_list_search = soup.select_one('div.area_list_search')\n",
    "        list_search_blog = area_list_search.select('div.list_search_blog')\n",
    "\n",
    "        # 검색 결과 개수\n",
    "        raw_blog_search_number = soup.select_one('div.search_information em.search_number').text\n",
    "        blog_search_number = int(re.sub('[^0-9]', '', raw_blog_search_number))\n",
    "\n",
    "        # 검색 결과 페이지 수\n",
    "        max_blog_search_page_num = int(np.ceil(blog_search_number / len(list_search_blog)))\n",
    "        \n",
    "        print('='*50)\n",
    "        print('검색어 :', keyword)\n",
    "        print('글/블로그 선택 :', tab_option)\n",
    "        print('정렬 순서 :', orderby.replace('sim', '관련도순').replace('recentdate', '최신순'))\n",
    "        print('검색 결과 개수 :', blog_search_number)\n",
    "        print('검색 결과 페이지 수 :', max_blog_search_page_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수집할 포스트 페이지 수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 포스트 페이지 수 : 51986\n",
      "수집할 포스트 페이지 수: 5\n"
     ]
    }
   ],
   "source": [
    "# 수집할 포스트 페이지 설정\n",
    "while True:\n",
    "    try:\n",
    "        print(f'최대 포스트 페이지 수 : {max_post_search_page_num}')\n",
    "        post_crawling_page_num = int(input(f\"수집할 포스트 페이지 수를 입력하세요(숫자만 입력) : \"))\n",
    "        if post_crawling_page_num <= 0:\n",
    "            print(\"0보다 큰 숫자를 입력하세요.\")\n",
    "            continue\n",
    "        if post_crawling_page_num > max_post_search_page_num:\n",
    "            print('입력한 숫자 :', post_crawling_page_num)\n",
    "            print(f\"입력한 숫자가 검색 결과 페이지 수보다 큽니다. {max_post_search_page_num}로 설정합니다.\")\n",
    "            post_crawling_page_num = max_post_search_page_num\n",
    "        break\n",
    "    except ValueError:\n",
    "        print(\"유효한 숫자를 입력하세요.\")\n",
    "\n",
    "print(f\"수집할 포스트 페이지 수: {post_crawling_page_num}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수집할 블로그 페이지 수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 블로그 페이지 수 : 20\n",
      "수집할 블로그 페이지 수: 5\n"
     ]
    }
   ],
   "source": [
    "# 수집할 블로그 페이지 설정\n",
    "while True:\n",
    "    try:\n",
    "        print(f'최대 블로그 페이지 수 : {max_blog_search_page_num}')\n",
    "        blog_crawling_page_num = int(input(f\"수집할 블로그 페이지 수를 입력하세요(숫자만 입력) : \"))\n",
    "        if blog_crawling_page_num <= 0:\n",
    "            print(\"0보다 큰 숫자를 입력하세요.\")\n",
    "            continue\n",
    "        if blog_crawling_page_num > max_blog_search_page_num:\n",
    "            print('입력한 숫자 :', blog_crawling_page_num)\n",
    "            print(f\"입력한 숫자가 검색 결과 페이지 수보다 큽니다. {max_blog_search_page_num}로 설정합니다.\")\n",
    "            blog_crawling_page_num = max_blog_search_page_num\n",
    "        break\n",
    "    except ValueError:\n",
    "        print(\"유효한 숫자를 입력하세요.\")\n",
    "\n",
    "print(f\"수집할 블로그 페이지 수: {blog_crawling_page_num}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 저장 위치 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아이폰_16'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_keyword = keyword.replace(' ', '_')\n",
    "file_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 날짜\n",
    "current_date = datetime.today().strftime('%Y%m%d')\n",
    "# 현재 경로 확인\n",
    "code_path = os.getcwd().replace('\\\\', '/')\n",
    "# 수집한 파일 저장할 폴더 생성\n",
    "crawled_folder_path = os.path.join(code_path, 'crawled_data', 'naver_blog', current_date)\n",
    "os.makedirs(crawled_folder_path, exist_ok=True)\n",
    "# 저장할 파일 경로\n",
    "current_datetime = datetime.today().strftime('%Y%m%d_%p_%I%M%S')\n",
    "file_path = os.path.join(crawled_folder_path, f'naver_blog_{file_keyword}_{current_datetime}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장 파일 경로 : c:/Users/kbjoo/Documents/Google_Drive/GitHub/my_projects/crawling/naver\\crawled_data\\naver_blog\\20250115\\naver_blog_아이폰_16_20250115_PM_114728.xlsx\n",
      "저장완료\n"
     ]
    }
   ],
   "source": [
    "# 페이지 수집\n",
    "sheet_name_list = ['글', '블로그']\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n",
    "    for tab_option in sheet_name_list:\n",
    "        if tab_option == '글':\n",
    "            title_list = []\n",
    "            text_list = []\n",
    "            name_author_list = []\n",
    "            name_blog_list = []\n",
    "            date_list = []\n",
    "            post_link_list = []\n",
    "            author_blog_link_list = []\n",
    "\n",
    "            for page_num in range(1, post_crawling_page_num + 1):\n",
    "                if rangetype == 'PERIOD':\n",
    "                    keyword_url = f'https://section.blog.naver.com/Search/Post.naver?pageNo={page_num}&rangeType={rangetype}&orderBy={orderby}&&startDate={startdate}&endDate={enddate}&keyword={keyword}'\n",
    "                else:\n",
    "                    keyword_url = f'https://section.blog.naver.com/Search/Post.naver?pageNo={page_num}&rangeType={rangetype}&orderBy={orderby}&keyword={keyword}'\n",
    "\n",
    "                driver.get(keyword_url)\n",
    "                driver.implicitly_wait(10) # 페이지 로드 될 때까지 기다리지만 로드 되는 순간 종료\n",
    "                time.sleep(random.uniform(1, 3))\n",
    "\n",
    "                page = driver.page_source\n",
    "                soup = bs(page, 'html.parser')\n",
    "                # print(soup.title.text)\n",
    "                \n",
    "                area_list_search = soup.select_one('div.area_list_search')\n",
    "                list_search_post = area_list_search.select('div.list_search_post')\n",
    "\n",
    "                for post in list_search_post:\n",
    "                    title = post.select_one('span.title').text\n",
    "                    text = post.select_one('a.text').text\n",
    "                    name_author = post.select_one('em.name_author').text\n",
    "                    name_blog = post.select_one('span.name_blog').text\n",
    "                    date = post.select_one('span.date').text\n",
    "                    post_link = post.select_one('a.desc_inner')['href']\n",
    "                    author_blog_link = post.select_one('a.author')['href']\n",
    "\n",
    "                    title_list.append(title)\n",
    "                    text_list.append(text)\n",
    "                    name_author_list.append(name_author)\n",
    "                    name_blog_list.append(name_blog)\n",
    "                    date_list.append(date)\n",
    "                    post_link_list.append(post_link)\n",
    "                    author_blog_link_list.append(author_blog_link)\n",
    "\n",
    "            # print(len(title_list), len(text_list), len(name_author_list), len(name_blog_list), len(date_list), len(post_link_list), len(author_blog_link_list))\n",
    "\n",
    "            # 데이터 프레임 생성\n",
    "            post_dict = {\n",
    "                'title': title_list,\n",
    "                'text': text_list,\n",
    "                'name_author': name_author_list,\n",
    "                'name_blog': name_blog_list,\n",
    "                'date': date_list,\n",
    "                'post_link': post_link_list,\n",
    "                'author_blog_link': author_blog_link_list\n",
    "            }\n",
    "            post_df = pd.DataFrame(post_dict)\n",
    "            post_df.to_excel(writer, sheet_name=tab_option, index=False)\n",
    "            # print(post_df.shape)\n",
    "\n",
    "        elif tab_option == '블로그':\n",
    "            text_blog_list = []\n",
    "            blog_intro_list = []\n",
    "            name_author_list = []\n",
    "            blog_link_list = []\n",
    "            for page_num in range(1, blog_crawling_page_num + 1):\n",
    "                keyword_url = f'https://section.blog.naver.com/Search/Blog.naver?pageNo={page_num}&orderBy={orderby}&keyword={keyword}'\n",
    "\n",
    "                driver.get(keyword_url)\n",
    "                driver.implicitly_wait(10) # 페이지 로드 될 때까지 기다리지만 로드 되는 순간 종료\n",
    "                time.sleep(random.uniform(1, 3))\n",
    "\n",
    "                page = driver.page_source\n",
    "                soup = bs(page, 'html.parser')\n",
    "                # print(soup.title.text)\n",
    "\n",
    "                area_list_search = soup.select_one('div.area_list_search')\n",
    "                list_search_blog = area_list_search.select('div.list_search_blog')\n",
    "\n",
    "                for blog in list_search_blog:\n",
    "                    text_blog = blog.select_one('em.text_blog').text\n",
    "                    if blog.select_one('p.blog_intro').text == '':\n",
    "                        blog_intro = np.nan\n",
    "                    else:\n",
    "                        blog_intro = blog.select_one('p.blog_intro').text\n",
    "                    name_author = blog.select_one('em.name_author').text\n",
    "                    blog_link = blog.select_one('a.name_blog')['href']\n",
    "                    # print(text_blog, blog_intro, name_author, blog_link)\n",
    "\n",
    "                    text_blog_list.append(text_blog)\n",
    "                    blog_intro_list.append(blog_intro)\n",
    "                    name_author_list.append(name_author)\n",
    "                    blog_link_list.append(blog_link)\n",
    "\n",
    "                # print(len(text_blog_list), len(blog_intro_list), len(name_author_list), len(blog_link_list))\n",
    "            blog_dict = {\n",
    "                'text_blog': text_blog_list,\n",
    "                'blog_intro': blog_intro_list,\n",
    "                'name_author': name_author_list,\n",
    "                'blog_link': blog_link_list\n",
    "            }\n",
    "            blog_df = pd.DataFrame(blog_dict)\n",
    "            blog_df.to_excel(writer, sheet_name=tab_option, index=False)\n",
    "            # print(blog_df.shape)\n",
    "\n",
    "    print('저장 파일 경로 :', file_path)\n",
    "    print('저장완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
